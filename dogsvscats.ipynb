{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tflearn\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.estimator import regression\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = \"data/train/\"\n",
    "TEST = \"data/test1/\"\n",
    "SIZE = 50\n",
    "LR = 0.001\n",
    "MODEL_NAME = 'models/dogsvscats-{}.model'.format(LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_grayscale(filename, shape):\n",
    "    return cv2.resize(cv2.imread(filename, cv2.IMREAD_GRAYSCALE), shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    label = filename.split('.')[0]\n",
    "    if label == 'cat':\n",
    "        return (1,0)\n",
    "    elif label == 'dog':\n",
    "        return (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_data():\n",
    "    train = []\n",
    "    for image in tqdm(os.listdir(TRAIN)):\n",
    "        label = load_data(image)\n",
    "        full_path = os.path.join(TRAIN, image)\n",
    "        image = load_image_grayscale(full_path, (SIZE, SIZE))\n",
    "        train.append([np.array(image),np.array(label)])\n",
    "    random.shuffle(train)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_data():\n",
    "    test_data = []\n",
    "    for image in tqdm(os.listdir(TEST)):\n",
    "        full_path = os.path.join(TEST, image)\n",
    "        image_class = image.split('.')[0]\n",
    "        image = load_image_grayscale(full_path, (SIZE, SIZE))\n",
    "        test_data.append([np.array(image), image_class])\n",
    "    random.shuffle(test_data)\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [07:36<00:00, 54.73it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = generate_train_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/PycharmProjects/Pandas Practice/venv/lib/python3.6/site-packages/tflearn/initializations.py:119: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "WARNING:tensorflow:From /home/user/PycharmProjects/Pandas Practice/venv/lib/python3.6/site-packages/tflearn/objectives.py:66: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "cnn = input_data(shape=[None, SIZE, SIZE, 1], name='input')\n",
    "\n",
    "cnn = conv_2d(cnn, 32, 5, activation='relu')\n",
    "cnn = max_pool_2d(cnn, 5)\n",
    "\n",
    "cnn = conv_2d(cnn, 64, 5, activation='relu')\n",
    "cnn = max_pool_2d(cnn, 5)\n",
    "\n",
    "cnn = conv_2d(cnn, 32, 5, activation='relu')\n",
    "cnn = max_pool_2d(cnn, 5)\n",
    "\n",
    "cnn = conv_2d(cnn, 64, 5, activation='relu')\n",
    "cnn = max_pool_2d(cnn, 5)\n",
    "\n",
    "cnn = conv_2d(cnn, 32, 5, activation='relu')\n",
    "cnn = max_pool_2d(cnn, 5)\n",
    "\n",
    "cnn = conv_2d(cnn, 32, 5, activation='relu')\n",
    "cnn = max_pool_2d(cnn, 5)\n",
    "\n",
    "\n",
    "cnn = fully_connected(cnn, 1024, activation='relu')\n",
    "cnn = dropout(cnn, 0.8)\n",
    "\n",
    "cnn = fully_connected(cnn, 2, activation='softmax')\n",
    "cnn = regression(cnn, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
    "\n",
    "model = tflearn.DNN(cnn, tensorboard_dir='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data[:-500]\n",
    "test = train_data[-500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(list(map(lambda t: t[0], train))).reshape(-1,SIZE,SIZE,1)\n",
    "y_train = np.array(list(map(lambda t: t[1], train)))\n",
    "\n",
    "X_test = np.array(list(map(lambda t: t[0], test))).reshape(-1,SIZE,SIZE,1)\n",
    "y_test = np.array(list(map(lambda t: t[1], test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24500, 50, 50, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 3063  | total loss: \u001b[1m\u001b[32m0.34242\u001b[0m\u001b[0m | time: 171.856s\n",
      "| Adam | epoch: 008 | loss: 0.34242 - acc: 0.8476 -- iter: 24448/24500\n",
      "Training Step: 3064  | total loss: \u001b[1m\u001b[32m0.35345\u001b[0m\u001b[0m | time: 174.159s\n",
      "| Adam | epoch: 008 | loss: 0.35345 - acc: 0.8441 | val_loss: 0.52906 - val_acc: 0.7620 -- iter: 24500/24500\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model.fit({'input': X_train}, {'targets': y_train}, n_epoch=7, \n",
    "          validation_set=({'input': X_test}, {'targets': y_test}), \n",
    "          snapshot_step=500, show_metric=True, run_id=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/home/user/PycharmProjects/Pandas Practice/dogsvscats/models/dogsvscats-0.001.model is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "model.save(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/user/PycharmProjects/Pandas Practice/dogsvscats/models/dogsvscats-0.001.model\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(f'{MODEL_NAME}.meta'):\n",
    "    model.load(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = load_image_grayscale(\"images/cat.0.jpg\", (SIZE, SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image.reshape(-1, SIZE, SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = ('cat', 'dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector[np.argmax(model.predict(image))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test_images = list(map(lambda i: 'images/'+i, images))\n",
    "my_test_images = list(map(lambda i: load_image_grayscale(i, (SIZE, SIZE)), my_test_images))\n",
    "my_test_images = list(map(lambda i: i.reshape(-1, SIZE, SIZE, 1), my_test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 0.750589907169342 % it is a cat\n",
      "Real answer: it is a cat.\n",
      "path: images/cat.0.jpg\n",
      "\n",
      "With 0.8083493113517761 % it is a dog\n",
      "Real answer: it is a cat.\n",
      "path: images/cat.1.jpg\n",
      "\n",
      "With 0.7114077210426331 % it is a dog\n",
      "Real answer: it is a cat.\n",
      "path: images/cat.3.jpg\n",
      "\n",
      "With 0.5466014742851257 % it is a cat\n",
      "Real answer: it is a dog.\n",
      "path: images/dog.1.jpg\n",
      "\n",
      "With 0.9594040513038635 % it is a dog\n",
      "Real answer: it is a cat.\n",
      "path: images/cat.2.jpg\n",
      "\n",
      "With 0.9298297762870789 % it is a dog\n",
      "Real answer: it is a dog.\n",
      "path: images/dog.0.jpg\n",
      "\n",
      "With 0.7481564283370972 % it is a dog\n",
      "Real answer: it is a dog.\n",
      "path: images/dog.2.jpg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for img, real in zip(my_test_images, images):\n",
    "    ans = model.predict(img)[0]\n",
    "    print(f'With {max(ans)} % it is a {detector[np.argmax(ans)]}')\n",
    "    print(f'Real answer: it is a {real[:4]}')\n",
    "    print(f'path: images/{real}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
